\section*{\zihao{2} \centering 摘要}

\vskip0.5cm
空间定位是移动机器人、无人车、AR/VR眼镜等最基本的技术之一。不失一般地，我们统称这些应用场景为机器人。所谓空间定位，即利用一种或多种传感器，估计机器人位姿的过程。虽然单个传感器能够实现空间定位，比如通过激光SLAM激光雷达能够输出绝对尺度的位姿，但是利用传感器之间的互补特性，或者增加冗余的传感器，能够极大地提高定位系统的精度和鲁棒性。因此，实际的定位系统往往是多传感器融合定位系统。所谓传感器的互补特征，比如单目相机和IMU，相机能够以实时的频率(30Hz)稳定追踪环境的特征而无法直接得到绝对尺度相关信息，而IMU则能够以很高的频率(高达1KHz)测量绝对尺度的加速度和角速度信息。因此，以单目相机和IMU融合的定位系统(VINS)能够准确并鲁棒输出高帧率的位姿，近些年来得到了极大的关注和发展。所谓传感器的冗余设计，指使用两个或多个的相同类型的传感器。比如单目相机换成双目，在有共视的情况下，可以得到绝对尺度的位姿；非共视情况下，由于FOV增加，因此更加不容易出现位姿追踪丢失的情形。又如单GPS换成双GPS后，就可以利用差分方法得到更准确的观测，避免构建复杂的观测模型。

本书围绕空间定位，系统地介绍了几种常见的传感器建模及其标定方法。本书关注怎么用传感器做定位，比如TOF，我们重点不是关注TOF出深度需要标哪些参数，而是拿到带深度的TOF，用来做定位(比如RGBD-SLAM)，还需要标定哪些参数。当然，TOF出深度的原理，建模以及TOF相机的类型本书也会提及。又如激光雷达，本书重点不是关注激光雷达出点云需要标哪些参数，而是拿到点云的雷达，用来做定位(比如激光-SLAM)，还需要标定哪些参数。当然，雷达出点云的原理，建模以及激光雷达的类型，本着点到为止的原则，本书也会提及。

具体地，对于每一种介绍的传感器，会先简单介绍其工作原理。然后从定位的角度出发，介绍其数学模型。接着，如果传感器自身需要或者能够独立不依赖别的传感器标定，则会介绍其独立标定方法。以IMU为例，IMU的内参包含噪声系数(噪声和随机游走)和系统误差系数(轴偏、尺度因子等)，在相应的章节中，会系统介绍这些独立方法，并选择其中一种进行详细的描述。

多传感器标定一般包含内参和外参标定。内参一般指传感器建模所涉及的参数，如相机的内参，一般包含光心、焦距和畸变这些参数。外参指传感器之间的相对位姿和时延。对于传感器的内参，往往有独立的方法可以标定。而外参则可以采用联合标定的方法来标定。特别地，在联合标定中，选择能够提供相对准确位姿的传感器为参考，利用其位姿构建样条。通过样条和传感器的内外参，可以很方便地把传感器之间的测量统一起来，构建联合的目标优化函数。利用非线性优化工具如Ceres，最小化目标函数，则可以同时得到传感器的内外参。其框架如下图\ref{fig-calibration-framework}所示。\\

\begin{figure}[thpb]
	\centering
	\includegraphics[scale=1.0]{figure/intro/calibration_framework}
	\caption{CalibX标定框架}
	\label{fig-calibration-framework}
\end{figure}

\textbf{关键词:}  噪声模型， 算法原理 ，数学模型，误差分析，标定
\addcontentsline{toc}{section}{摘要}

\clearpage
\section*{\zihao{2} \centering \textbf{Abstract} }
   %用了Times New Roman字体来美化观感

In this book calibration methods for common sensors are introduced.\\

\textbf{Key Words:} Noise model, Algorithm Theory, Mathematical Model, Error analysis, Calibration
\addcontentsline{toc}{section}{Abstract}




